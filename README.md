#  Pipeline Big Data - Analyse du Trafic Urbain et MobilitÃ© Intelligente

##  Table des matiÃ¨res
1. [Vue d'ensemble](#-vue-densemble)
2. [Architecture du systÃ¨me](#ï¸-architecture-du-systÃ¨me)
3. [PrÃ©requis](#-prÃ©requis)
4. [Installation et dÃ©marrage](#-installation-et-dÃ©marrage)
5. [Structure du projet](#-structure-du-projet)
6. [Guide d'utilisation](#-guide-dutilisation)
7. [VÃ©rification du pipeline](#-vÃ©rification-du-pipeline)
8. [Dashboards et visualisation](#-dashboards-et-visualisation)
9. [Troubleshooting](#-troubleshooting)
10. [MÃ©triques et KPIs](#-mÃ©triques-et-kpis)

---

##  Vue d'ensemble

Ce projet implÃ©mente un **pipeline Big Data end-to-end** pour l'analyse du trafic urbain dans le cadre d'une Smart City. Il permet de :

- âœ… **Collecter** des donnÃ©es de trafic en temps rÃ©el depuis des capteurs simulÃ©s
- âœ… **IngÃ©rer** les donnÃ©es via Apache Kafka
- âœ… **Stocker** dans un Data Lake HDFS
- âœ… **Traiter** avec Apache Spark
- âœ… **Visualiser** avec Grafana
- âœ… **Orchestrer** avec Apache Airflow
- âœ… **Monitorer** avec Prometheus

###  Contexte du projet

Dans le cadre d'une Smart City, les villes modernes dÃ©ploient des capteurs urbains (camÃ©ras, boucles magnÃ©tiques, capteurs IoT, applications mobiles) pour collecter en continu des donnÃ©es de trafic routier. Ce projet rÃ©pond Ã  la problÃ©matique suivante :

> **Comment concevoir et implÃ©menter un pipeline Big Data capable de collecter des donnÃ©es de trafic urbain en temps rÃ©el, de les stocker dans un Data Lake, de les traiter efficacement, puis de produire des indicateurs exploitables pour la gestion intelligente de la mobilitÃ© ?**

---

##  Architecture du systÃ¨me

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ARCHITECTURE PIPELINE                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Capteurs IoT   â”‚ â—„â”€â”€ Simulation de 50 capteurs urbains
â”‚   (Producer)    â”‚     GÃ©nÃ¨re des Ã©vÃ©nements toutes les secondes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ JSON events
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Apache Kafka   â”‚ â—„â”€â”€ Streaming temps rÃ©el
â”‚  Topic: traffic â”‚     Gestion des flux IoT
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka Consumer â”‚ â—„â”€â”€ Ingestion et organisation des donnÃ©es
â”‚   + Prometheus  â”‚     MÃ©triques exposÃ©es pour monitoring
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Ã‰criture HDFS
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HDFS (Raw)    â”‚ â—„â”€â”€ Data Lake - Zone Raw
â”‚ /data/raw/trafficâ”‚    Structure partitionnÃ©e par date/heure/zone
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Apache Spark   â”‚ â—„â”€â”€ Traitement distribuÃ© et agrÃ©gation
â”‚  Batch Process  â”‚     Calcul des statistiques et KPIs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Parquet format
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HDFS (Analytics)â”‚ â—„â”€â”€ Zone Analytics - Format optimisÃ©
â”‚ /data/analytics â”‚     RÃ©sultats prÃªts pour l'analyse
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Grafana      â”‚ â—„â”€â”€ Dashboards interactifs
â”‚  + Prometheus   â”‚     Visualisation temps rÃ©el des KPIs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²
         â”‚ Orchestration
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Apache Airflow  â”‚ â—„â”€â”€ Automatisation du pipeline
â”‚   DAG hourly    â”‚     Workflow complet toutes les heures
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

###  Flux de donnÃ©es

1. **GÃ©nÃ©ration** : Le producer Python simule 50 capteurs gÃ©nÃ©rant des Ã©vÃ©nements JSON
2. **Streaming** : Les Ã©vÃ©nements sont publiÃ©s dans Kafka (topic `traffic-events`)
3. **Ingestion** : Le consumer Kafka lit les messages et les Ã©crit dans HDFS
4. **Stockage Raw** : Organisation hiÃ©rarchique par `date`/`heure`/`zone`
5. **Traitement** : Spark lit les donnÃ©es raw et calcule les agrÃ©gations
6. **Stockage Analytics** : RÃ©sultats sauvegardÃ©s en Parquet pour l'analyse
7. **Visualisation** : Grafana affiche les mÃ©triques en temps rÃ©el
8. **Orchestration** : Airflow automatise l'exÃ©cution du pipeline toutes les heures

---

##  PrÃ©requis

### Logiciels requis

- **Docker** (version 20.10+)
- **Docker Compose** (version 2.0+)
- **Git**
- **Au moins 8 GB de RAM disponible**
- **20 GB d'espace disque**

### VÃ©rifier les versions

```bash
docker --version
# Docker version 20.10.x ou supÃ©rieur

docker-compose --version
# Docker Compose version 2.x.x ou supÃ©rieur
```

### 2. Structure des dossiers

CrÃ©ez la structure suivante si elle n'existe pas :

```
traffic-big-data-pipeline/
â”œâ”€â”€ producer/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ traffic_producer.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ consumer/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ kafka_to_hdfs.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ spark_job.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ traffic_pipeline.py
â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ provisioning/
â”‚       â”œâ”€â”€ datasources/
â”‚       â”‚   â””â”€â”€ datasources.yml
â”‚       â””â”€â”€ dashboards/
â”‚           â”œâ”€â”€ dashboard.yml
â”‚           â””â”€â”€ traffic_analytics.json
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

### 3. DÃ©marrer les services

```bash
# DÃ©marrer tous les services en arriÃ¨re-plan
docker-compose up -d

# VÃ©rifier que tous les conteneurs sont actifs
docker-compose ps
```

** Temps de dÃ©marrage estimÃ© : 2-3 minutes**

Vous devriez voir une sortie similaire Ã  :

```
NAME                  STATUS
airflow-postgres      Up (healthy)
airflow-scheduler     Up
airflow-webserver     Up
datanode              Up
grafana               Up
kafka                 Up (healthy)
kafka-consumer        Up
kafka-producer        Up
namenode              Up (healthy)
prometheus            Up
spark                 Up
zookeeper             Up (healthy)
```

### 4. AccÃ©der aux interfaces web

| Service | URL | Identifiants | Description |
|---------|-----|--------------|-------------|
| **Airflow** | http://localhost:8080 | admin / admin | Orchestration du pipeline |
| **Grafana** | http://localhost:3000 | admin / admin | Dashboards et visualisation |
| **Prometheus** | http://localhost:9090 | - | MÃ©triques et monitoring |
| **HDFS NameNode** | http://localhost:9870 | - | Interface web HDFS |
| **Kafka** | localhost:9092 | - | Broker Kafka (CLI uniquement) |

---

##  Structure du projet

### Producer (GÃ©nÃ©rateur de donnÃ©es)

**Fichier** : `producer/traffic_producer.py`

**RÃ´le** : Simuler des capteurs urbains IoT gÃ©nÃ©rant des Ã©vÃ©nements de trafic

**CaractÃ©ristiques** :
- 50 capteurs simulÃ©s (`sensor_001` Ã  `sensor_050`)
- 20 routes diffÃ©rentes (`road_01` Ã  `road_20`)
- 5 zones gÃ©ographiques (Centre, Nord, Sud, Est, Ouest)
- 3 types de routes (autoroute, avenue, rue)
- GÃ©nÃ©ration adaptative selon l'heure :
  - **Heures de pointe** (7h-9h, 17h-20h) : Trafic dense
  - **Heures creuses** (22h-6h) : Trafic faible
  - **Heures normales** : Trafic modÃ©rÃ©

**Exemple d'Ã©vÃ©nement gÃ©nÃ©rÃ©** :

```json
{
  "sensor_id": "sensor_042",
  "road_id": "road_15",
  "road_type": "avenue",
  "zone": "Centre",
  "vehicle_count": 150,
  "average_speed": 25.8,
  "occupancy_rate": 75.4,
  "event_time": "2026-01-10T14:30:45.123456"
}
```

**Commande pour voir les logs** :

```bash
docker-compose logs -f kafka-producer
```

---

### Consumer (HDFS Writer)

**Fichier** : `consumer/kafka_to_hdfs.py`

**RÃ´le** : Consommer les messages Kafka et les Ã©crire dans HDFS

**FonctionnalitÃ©s** :
- Consommation temps rÃ©el depuis Kafka
- Organisation hiÃ©rarchique des donnÃ©es :
  ```
  /data/raw/traffic/
    date=2026-01-10/
      hour=14/
        zone=Centre/
          traffic.json
        zone=Nord/
          traffic.json
  ```
- Buffering pour optimiser les Ã©critures HDFS
- Exposition de mÃ©triques Prometheus sur le port 8000
- Gestion des erreurs et reconnexion automatique

**MÃ©triques exposÃ©es** :
- `traffic_events_total` : Nombre total d'Ã©vÃ©nements traitÃ©s
- `traffic_vehicle_count` : Nombre de vÃ©hicules par zone
- `traffic_average_speed` : Vitesse moyenne par zone
- `traffic_occupancy_rate` : Taux d'occupation par zone
- `traffic_congestion_level` : Niveau de congestion calculÃ©
- `hdfs_bytes_written` : Octets Ã©crits dans HDFS

**Commande pour voir les logs** :

```bash
docker-compose logs -f kafka-consumer
```

---

### Spark Job (Traitement)

**Fichier** : `spark/spark_job.py`

**RÃ´le** : Traiter les donnÃ©es raw et produire des analytics

**Traitements effectuÃ©s** :

1. **Statistiques par zone** :
   - Nombre total d'Ã©vÃ©nements
   - Nombre moyen de vÃ©hicules
   - Vitesse moyenne
   - Taux d'occupation moyen

2. **Statistiques par type de route** :
   - Trafic moyen par type (autoroute, avenue, rue)
   - Vitesse moyenne par type

3. **DÃ©tection des zones congestionnÃ©es** :
   - CritÃ¨res : vitesse < 40 km/h ET occupation > 60%
   - Liste des zones nÃ©cessitant une intervention

**RÃ©sultats sauvegardÃ©s** :
- `/data/analytics/traffic/by_zone/` (format Parquet)
- `/data/analytics/traffic/by_road_type/` (format Parquet)
- `/data/analytics/traffic/congested_zones/` (format Parquet)

**Commande pour exÃ©cuter manuellement** :

```bash
docker exec spark spark-submit \
  --master local[*] \
  --driver-memory 2g \
  /app/spark_job.py
```

---

### Airflow DAG (Orchestration)

**Fichier** : `airflow/dags/traffic_pipeline.py`

**RÃ´le** : Automatiser l'exÃ©cution du pipeline complet

**Workflow du DAG** :

```
check_services â†’ wait_for_data â†’ check_hdfs_data â†’ 
spark_processing â†’ validate_results â†’ generate_report
```

**TÃ¢ches** :

1. **check_services** : VÃ©rifier que tous les conteneurs sont actifs
2. **wait_for_data** : Attendre 60 secondes pour accumuler des donnÃ©es
3. **check_hdfs_data** : VÃ©rifier la prÃ©sence de donnÃ©es dans HDFS
4. **spark_processing** : Lancer le job Spark
5. **validate_results** : VÃ©rifier que les analytics ont Ã©tÃ© gÃ©nÃ©rÃ©s
6. **generate_report** : Produire un rapport d'exÃ©cution

**Configuration** :
- **FrÃ©quence** : Toutes les heures (`@hourly`)
- **PropriÃ©taire** : noura
- **Retries** : 2 tentatives en cas d'Ã©chec
- **Timeout** : 30 minutes par tÃ¢che

**AccÃ¨s** : http://localhost:8080

---

##  Guide d'utilisation

### Ã‰tape 1 : DÃ©marrer le pipeline

```bash
# 1. DÃ©marrer tous les services
docker-compose up -d

# 2. VÃ©rifier que tous les conteneurs sont UP
docker-compose ps

# 3. Suivre les logs gÃ©nÃ©raux
docker-compose logs -f
```
<img width="955" height="447" alt="image" src="https://github.com/user-attachments/assets/c24bcac0-db9e-48fe-afc2-78765454d7b7" />

**Indicateurs de succÃ¨s** :
- âœ… Tous les services affichent "Up" ou "Up (healthy)"
- âœ… Le producer affiche : `EnvoyÃ© : {...}`
- âœ… Le consumer affiche : `ğŸ’¾ Ã‰crit X Ã©vÃ©nements`

---

### Ã‰tape 2 : VÃ©rifier Kafka

```bash
# Lister les topics Kafka
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Vous devriez voir : traffic-events

# Consommer quelques messages pour vÃ©rifier
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic traffic-events \
  --from-beginning \
  --max-messages 5
```


**Exemple de sortie attendue** :

```json
{"sensor_id":"sensor_003","road_id":"road_12","road_type":"avenue","zone":"Nord","vehicle_count":85,"average_speed":45.2,"occupancy_rate":52.1,"event_time":"2026-01-10T14:30:00"}
```
#### kafka-producer
<img width="936" height="466" alt="image" src="https://github.com/user-attachments/assets/caff4336-b6a8-467b-9211-4d37204bad77" />


#### kafka-consumer
<img width="960" height="746" alt="image" src="https://github.com/user-attachments/assets/096833fd-8a38-4f4d-90cd-1ddae15dbc60" />


**VÃ©rifier le lag du consumer** :

```bash
docker exec kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe --group hdfs-consumer-group
```

---

### Ã‰tape 3 : VÃ©rifier HDFS

#### Via ligne de commande

```bash
# 1. Lister la structure principale
docker exec namenode hdfs dfs -ls /data/raw/traffic/

# Sortie attendue :
# drwxr-xr-x   - root supergroup  date=2026-01-10

# 2. Voir les dossiers par date
docker exec namenode hdfs dfs -ls /data/raw/traffic/date=2026-01-10/

# 3. Voir les heures
docker exec namenode hdfs dfs -ls /data/raw/traffic/date=2026-01-10/hour=14/

# 4. Voir les zones
docker exec namenode hdfs dfs -ls /data/raw/traffic/date=2026-01-10/hour=14/

# 5. Lire le contenu d'un fichier (premiÃ¨res lignes)
docker exec namenode hdfs dfs -cat \
  /data/raw/traffic/date=2026-01-10/hour=14/zone=Centre/traffic.json | head -5

# 6. Voir la taille totale des donnÃ©es
docker exec namenode hdfs dfs -du -s -h /data/raw/traffic/
```
- Structure hiÃ©rarchique montrant date â†’ hour â†’ zone
- Contenu d'un fichier `traffic.json`
- Taille totale des donnÃ©es stockÃ©es
<img width="1592" height="653" alt="image" src="https://github.com/user-attachments/assets/894a7c43-53ef-43d8-ac2d-a546d16700c4" />

#### Via interface web HDFS

1. Ouvrir dans un navigateur : http://localhost:9870
2. Cliquer sur **Utilities** dans le menu
3. SÃ©lectionner **Browse the file system**
4. Naviguer vers `/data/raw/traffic/`
5. Explorer la structure date/hour/zone

** screenshot** :
- Page d'accueil HDFS montrant le cluster
- Navigation dans `/data/raw/traffic/`
- DÃ©tails d'un fichier JSON
<img width="1885" height="827" alt="image" src="https://github.com/user-attachments/assets/7e6a2862-6d21-49eb-bd34-cabd987c3a49" />

---

### Ã‰tape 4 : ExÃ©cuter le job Spark

#### MÃ©thode 1 : ExÃ©cution manuelle

```bash
docker exec spark spark-submit \
  --master local[*] \
  --driver-memory 2g \
  --executor-memory 2g \
  /app/spark_job.py
```

** Ã€ capturer en screenshot** :
- Logs Spark montrant :
  - `ğŸ“Š Nombre total d'Ã©vÃ©nements: X`
  - `âœ… Statistiques de trafic par zone:`
  - Tableau avec les statistiques
  - `âœ… Job Spark terminÃ© avec succÃ¨s!`

**Sortie attendue** :

```
ğŸš€ Spark Job - Traitement des donnÃ©es de trafic
ğŸ“– Lecture des donnÃ©es depuis: hdfs://namenode:9000/data/raw/traffic/...
ğŸ“Š Nombre total d'Ã©vÃ©nements: 5432

âœ… Statistiques de trafic par zone:
+------+------------+------------------+---------+--------------+
|zone  |total_events|avg_vehicle_count |avg_speed|avg_occupancy |
+------+------------+------------------+---------+--------------+
|Centre|1234        |125.5             |32.4     |68.2          |
|Nord  |1100        |95.3              |45.7     |52.1          |
...
```
<img width="1641" height="742" alt="image" src="https://github.com/user-attachments/assets/a6b5b4d0-c638-4b9a-9d13-c07e1e56af37" />


#### MÃ©thode 2 : Via Airflow (recommandÃ©)

Cette mÃ©thode sera dÃ©taillÃ©e Ã  l'Ã©tape 5.

#### VÃ©rifier les rÃ©sultats analytics

```bash
# Lister les dossiers analytics
docker exec namenode hdfs dfs -ls /data/analytics/traffic/

# Vous devriez voir :
# /data/analytics/traffic/by_zone/
# /data/analytics/traffic/by_road_type/
# /data/analytics/traffic/congested_zones/

# Voir la taille des rÃ©sultats
docker exec namenode hdfs dfs -du -s -h /data/analytics/traffic/by_zone/

# Lire quelques rÃ©sultats (format Parquet)
docker exec spark spark-shell --master local[*] <<EOF
val df = spark.read.parquet("hdfs://namenode:9000/data/analytics/traffic/by_zone")
df.show()
EOF
```

**ğŸ“¸Liste des dossiers analytics** :
- Contenu d'une table (by_zone, by_road_type, ou congested_zones)
---
<img width="1197" height="167" alt="image" src="https://github.com/user-attachments/assets/ec62cb40-f9c2-41c1-b685-a0d65799b59c" />


### Ã‰tape 5 : Utiliser Airflow

#### AccÃ©der Ã  l'interface Airflow

1. Ouvrir dans un navigateur : http://localhost:8080
2. Se connecter avec :
   - **Username** : `admin`
   - **Password** : `admin`


#### Activer le DAG

1. Dans la liste des DAGs, trouver `traffic_pipeline_big_data`
2. Cliquer sur le bouton **Toggle** (interrupteur) Ã  gauche pour l'activer
3. Le DAG devient actif et s'exÃ©cutera automatiquement toutes les heures

**ğŸ“¸ screenshot** :
<img width="1902" height="635" alt="image" src="https://github.com/user-attachments/assets/484f9de4-12f7-4767-b982-695b77d63e03" />


#### Lancer manuellement le DAG

1. Cliquer sur le nom du DAG `traffic_pipeline_big_data`
2. Cliquer sur le bouton **â–¶ï¸ (Play)** en haut Ã  droite
3. SÃ©lectionner **Trigger DAG**
4. Confirmer le lancement

**ğŸ“¸  screenshot** :
- Vue Graph montrant toutes les tÃ¢ches
- TÃ¢ches en cours d'exÃ©cution (jaune)
- Toutes les tÃ¢ches rÃ©ussies (vert)
<img width="1891" height="966" alt="image" src="https://github.com/user-attachments/assets/68da0ff1-990f-4661-aa36-44ab152dc017" />

#### Observer l'exÃ©cution

1. Cliquer sur le DAG pour voir les dÃ©tails
2. Choisir la vue **Graph** pour voir le workflow
3. Observer les tÃ¢ches qui s'exÃ©cutent :
   - ğŸŸ¡ Jaune : En cours
   - ğŸŸ¢ Vert : RÃ©ussi
   - ğŸ”´ Rouge : Ã‰chouÃ©


#### Vue dÃ©taillÃ©e des logs

1. Cliquer sur une tÃ¢che (ex: `spark_processing`)
2. SÃ©lectionner **Log**
3. Observer les logs dÃ©taillÃ©s de la tÃ¢che

**ğŸ“¸ Ã€ capturer en screenshot** :
- Logs de la tÃ¢che `check_hdfs_data` montrant les fichiers trouvÃ©s
- Logs de la tÃ¢che `spark_processing` montrant le succÃ¨s du job
- Logs de la tÃ¢che `generate_report` montrant le rapport final
<img width="1887" height="955" alt="image" src="https://github.com/user-attachments/assets/e000137d-e717-4141-add8-5fb4fe4996aa" />


### Ã‰tape 6 : Visualiser avec Grafana

#### AccÃ©der Ã  Grafana

1. Ouvrir dans un navigateur : http://localhost:3000
2. Se connecter avec :
   - **Username** : `admin`
   - **Password** : `admin`
3. (Optionnel) Changer le mot de passe ou cliquer sur "Skip"

** Page d'accueil de Grafana** :
<img width="1918" height="965" alt="image" src="https://github.com/user-attachments/assets/cbb52b11-28c3-4d4f-948f-44479497aa52" />


#### AccÃ©der au dashboard

1. Cliquer sur le menu hamburger (â˜°) en haut Ã  gauche
2. SÃ©lectionner **Dashboards**
3. Cliquer sur **Traffic Analytics - Smart City**

** Liste des dashboards** :
- Dashboard complet "Traffic Analytics - Smart City"
<img width="967" height="447" alt="image" src="https://github.com/user-attachments/assets/8d813daf-044a-4a8a-9103-581eecaeed63" />

#### Panels du dashboard

Le dashboard contient 5 panels principaux :

##### 1. Total Ã‰vÃ©nements (Stat Panel)

**Description** : Affiche le nombre total d'Ã©vÃ©nements traitÃ©s depuis le dÃ©marrage

**MÃ©triques** :
- Compteur : `traffic_events_total`
- Seuils de couleur :
  - ğŸŸ¢ Vert : < 1000 Ã©vÃ©nements
  - ğŸŸ¡ Jaune : 1000-5000 Ã©vÃ©nements
  - ğŸ”´ Rouge : > 5000 Ã©vÃ©nements

**ğŸ“¸ Ã€ capturer en screenshot** :
- Panel montrant le compteur total
  <img width="1423" height="381" alt="image" src="https://github.com/user-attachments/assets/4728ee9d-8f8b-45e8-bc7e-cb481f058bb4" />

---

##### 2. VÃ©hicules par Zone (Time Series)

**Description** : Graphique temporel montrant l'Ã©volution du nombre de vÃ©hicules par zone

**MÃ©triques** :
- SÃ©rie temporelle : `traffic_vehicle_count`
- Une courbe par zone (Centre, Nord, Sud, Est, Ouest)

**InterprÃ©tation** :
- Pics visibles pendant les heures de pointe
- Tendances diffÃ©rentes selon les zones
- Identification rapide des zones les plus frÃ©quentÃ©es

**screenshot** :
<img width="640" height="352" alt="image" src="https://github.com/user-attachments/assets/dc6a1e9b-409b-4f5a-b4b2-8da6b00ee70e" />


##### 3. Vitesse Moyenne (Gauge)

**Description** : Jauges circulaires montrant la vitesse moyenne par zone

**MÃ©triques** :
- Gauge : `traffic_average_speed`
- Une jauge par zone
- UnitÃ© : km/h

**Seuils de couleur** :
- ğŸ”´ Rouge : < 30 km/h (congestion)
- ğŸŸ¡ Jaune : 30-50 km/h (ralentissement)
- ğŸŸ¢ Vert : > 50 km/h (fluide)

**screenshot** :
- Ensemble des jauges pour toutes les zones
- Au moins une zone en rouge (congestion)
- Au moins une zone en vert (fluide)
<img width="630" height="377" alt="image" src="https://github.com/user-attachments/assets/40af6d4a-8c48-4d48-a0d5-9778c7165b0d" />

---

##### 4. Taux d'Occupation (Time Series)

**Description** : Ã‰volution du taux d'occupation de la route (0-100%)

**MÃ©triques** :
- SÃ©rie temporelle : `traffic_occupancy_rate`
- Une courbe par zone
- Ã‰chelle : 0-100%

**InterprÃ©tation** :
- Occupation Ã©levÃ©e (>70%) = risque de congestion
- Occupation faible (<30%) = trafic fluide

**screenshot** :
- Graphique montrant l'Ã©volution temporelle
- Courbes de diffÃ©rentes couleurs pour chaque zone
- Variation visible selon les heures
<img width="618" height="388" alt="image" src="https://github.com/user-attachments/assets/b639427d-38b1-4895-90a1-827c6bb1afd6" />

---

##### 5. Niveau de Congestion (Gauge)

**Description** : Score composite de congestion calculÃ© (0-100)

**Formule de calcul** :
```
Congestion = 0.4 Ã— (vehicle_count/200Ã—100) 
           + 0.4 Ã— ((110-speed)/110Ã—100) 
           + 0.2 Ã— occupancy_rate
```

**MÃ©triques** :
- Gauge : `traffic_congestion_level`
- Score de 0 Ã  100

**Seuils d'interprÃ©tation** :
- ğŸŸ¢ Vert : 0-40 (fluide)
- ğŸŸ¡ Jaune : 40-70 (modÃ©rÃ©)
- ğŸ”´ Rouge : 70-100 (congestionnÃ©)

**screenshot** :
- Jauges de congestion pour toutes les zones
- Au moins une zone en Ã©tat critique (rouge)
<img width="1913" height="592" alt="image" src="https://github.com/user-attachments/assets/eab5462a-3de9-4a39-b7cb-b994f154a935" />

---

#### FonctionnalitÃ©s avancÃ©es de Grafana

##### Filtrage temporel

En haut Ã  droite du dashboard :
1. Cliquer sur la sÃ©lection de temps (ex: "Last 1 hour")
2. Choisir une pÃ©riode :
   - Last 5 minutes
   - Last 15 minutes
   - Last 1 hour
   - Last 3 hours
   - Custom range

##### RafraÃ®chissement automatique

1. En haut Ã  droite, cliquer sur l'icÃ´ne de rafraÃ®chissement
2. SÃ©lectionner "5s" pour un rafraÃ®chissement toutes les 5 secondes
3. Observer les graphiques se mettre Ã  jour en temps rÃ©el


##### Zoom sur un graphique

1. Cliquer et glisser sur un graphique pour sÃ©lectionner une pÃ©riode
2. Le graphique zoome automatiquement
3. Cliquer sur "Zoom out" pour revenir

##### Export de dashboard

1. Cliquer sur l'icÃ´ne de partage en haut du dashboard
2. SÃ©lectionner "Export"
3. TÃ©lÃ©charger le fichier JSON

---

### Ã‰tape 7 : VÃ©rifier Prometheus

#### AccÃ©der Ã  Prometheus

1. Ouvrir dans un navigateur : http://localhost:9090
2. Aucune authentification requise


#### VÃ©rifier les targets

1. Cliquer sur **Status** dans le menu
2. SÃ©lectionner **Targets**
3. VÃ©rifier que `kafka_consumer_metrics` est en **UP**

**Liste des targets** :

- Target `kafka_consumer_metrics` avec Ã©tat "UP" et endpoint `kafka-consumer:8000`
 ![Uploading image.pngâ€¦]()


#### ExÃ©cuter des requÃªtes PromQL

##### RequÃªte 1 : Taux d'Ã©vÃ©nements par seconde

```promql
rate(traffic_events_total[1m])
```

1. Copier la requÃªte dans la barre de recherche
2. Cliquer sur **Execute**
3. SÃ©lectionner l'onglet **Graph** pour voir l'Ã©volution

---

##### RequÃªte 2 : VÃ©hicules moyens par zone

```promql
avg(traffic_vehicle_count) by (zone)
```

**RÃ©sultat attendu** :
```
{zone="Centre"}    125.5
{zone="Nord"}      95.3
{zone="Sud"}       87.2
{zone="Est"}       102.1
{zone="Ouest"}     78.9
```
## Conclusion

Ce projet dÃ©montre la mise en place complÃ¨te d'un **pipeline Big Data end-to-end** pour l'analyse du trafic urbain dans le contexte d'une Smart City. L'architecture implÃ©mentÃ©e couvre l'ensemble des Ã©tapes essentielles d'un systÃ¨me de traitement de donnÃ©es massives en temps rÃ©el.

### Objectifs atteints

#### 1. Collecte de donnÃ©es en temps rÃ©el
- Simulation de 50 capteurs IoT urbains
- GÃ©nÃ©ration continue d'Ã©vÃ©nements de trafic
- Adaptation du trafic selon les heures (pointe, creuse, normale)
- Format JSON standardisÃ© et structurÃ©

#### 2. Ingestion streaming
- Apache Kafka pour la gestion des flux temps rÃ©el
- Producer capable de gÃ©nÃ©rer des milliers d'Ã©vÃ©nements
- Consumer avec gestion des erreurs et reconnexion automatique
- Exposition de mÃ©triques pour le monitoring

#### 3. Stockage distribuÃ© (Data Lake)
- HDFS comme systÃ¨me de stockage distribuÃ©
- Organisation hiÃ©rarchique par date/heure/zone
- Zone Raw pour les donnÃ©es brutes
- Zone Analytics pour les rÃ©sultats traitÃ©s

#### 4. Traitement Big Data
- Apache Spark pour le traitement distribuÃ©
- Calculs d'agrÃ©gations et statistiques complexes
- DÃ©tection des zones congestionnÃ©es
- Format Parquet optimisÃ© pour l'analyse

#### 5. Visualisation et dashboards
- Grafana avec dashboards interactifs
- 5 panels couvrant tous les KPIs mÃ©tier
- RafraÃ®chissement temps rÃ©el (5 secondes)
- Alertes visuelles par seuils de couleur

#### 6. Orchestration et automatisation
- Apache Airflow pour l'automatisation du pipeline
- DAG avec 6 tÃ¢ches interdÃ©pendantes
- ExÃ©cution automatique toutes les heures
- Gestion des erreurs et retry automatique

#### 7. Monitoring et observabilitÃ©
- Prometheus pour la collecte de mÃ©triques
- 7 mÃ©triques exposÃ©es par le consumer
- Supervision de la santÃ© des services
- RequÃªtes PromQL pour l'analyse avancÃ©e

### CompÃ©tences dÃ©montrÃ©es

Ce projet illustre la maÃ®trise des technologies et concepts suivants :

| Domaine | Technologies | CompÃ©tences |
|---------|-------------|-------------|
| **Streaming** | Kafka, Producer/Consumer | Traitement temps rÃ©el, gestion des flux IoT |
| **Stockage** | HDFS, Parquet | Data Lake, partitionnement, formats optimisÃ©s |
| **Traitement** | Apache Spark, PySpark | Calculs distribuÃ©s, agrÃ©gations, transformations |
| **Orchestration** | Apache Airflow | Workflows, DAGs, automatisation, scheduling |
| **Visualisation** | Grafana, Prometheus | Dashboards, mÃ©triques, KPIs, monitoring |
| **Infrastructure** | Docker, Docker Compose | Conteneurisation, orchestration, microservices |
| **DevOps** | CI/CD concepts | Automatisation, logging, healthchecks |

### RÃ©sultats mÃ©tier

Le pipeline produit des insights exploitables pour la gestion urbaine :

1. **Identification des zones critiques** en temps rÃ©el
2. **PrÃ©diction des congestions** basÃ©e sur des patterns historiques
3. **Optimisation du trafic** grÃ¢ce aux statistiques par type de route
4. **Aide Ã  la dÃ©cision** pour la planification urbaine
5. **Alertes automatiques** pour les interventions urgentes

### ScalabilitÃ© et Ã©volutions possibles

Le systÃ¨me est conÃ§u pour Ã©voluer :

**Court terme** :
- Augmentation du nombre de capteurs (scalabilitÃ© horizontale)
- Ajout de nouvelles zones gÃ©ographiques
- IntÃ©gration de donnÃ©es mÃ©tÃ©o pour corrÃ©lation

**Moyen terme** :
- Machine Learning pour la prÃ©diction de congestion
- API REST pour exposer les analytics
- SystÃ¨me de recommandation d'itinÃ©raires

**Long terme** :
- DÃ©ploiement sur Kubernetes pour haute disponibilitÃ©
- IntÃ©gration avec systÃ¨mes de feux intelligents
- Extension Ã  d'autres villes (multi-tenant)

### Valeur ajoutÃ©e pour une Smart City

Ce pipeline rÃ©pond aux enjeux majeurs de la mobilitÃ© urbaine :

- **RÃ©activitÃ©** : DÃ©tection des problÃ¨mes en quelques secondes
- **PrÃ©vention** : Anticipation des congestions avant qu'elles ne surviennent
- **Optimisation** : Meilleure allocation des ressources municipales
- **DurabilitÃ©** : RÃ©duction des Ã©missions par fluidification du trafic
- **Transparence** : DonnÃ©es accessibles via dashboards publics

### Apprentissages clÃ©s

1. **Architecture Lambda** : Combinaison de traitement batch (Spark) et streaming (Kafka)
2. **Data Lake moderne** : Organisation en zones (Raw, Processed, Analytics)
3. **ObservabilitÃ©** : L'importance du monitoring dÃ¨s la conception
4. **RÃ©silience** : Gestion des pannes et reprise automatique
5. **Performance** : Optimisations (partitionnement, formats, buffering)

### Conclusion finale

Ce projet dÃ©montre qu'un **pipeline Big Data robuste et scalable** peut Ãªtre mis en place avec des technologies open-source modernes. L'approche end-to-end, de la collecte Ã  la visualisation en passant par le traitement distribuÃ©, illustre parfaitement les dÃ©fis et solutions d'un systÃ¨me Big Data en production.

La combinaison de **Kafka, HDFS, Spark, Airflow, et Grafana** forme une stack technologique Ã©prouvÃ©e, capable de gÃ©rer des volumes massifs de donnÃ©es tout en fournissant des insights exploitables en temps rÃ©el.

Ce systÃ¨me est **prÃªt pour la production** et pourrait Ãªtre dÃ©ployÃ© dans une vÃ©ritable Smart City avec des ajustements mineurs pour s'adapter aux spÃ©cificitÃ©s locales.



## RÃ©fÃ©rences

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [Hadoop HDFS Guide](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html)
- [Grafana Documentation](https://grafana.com/docs/)
- [Prometheus Documentation](https://prometheus.io/docs/)

---

## Auteur

**Noura cherrad** - Projet Big Data : Analyse du Trafic Urbain et MobilitÃ© Intelligente



**nissrine el fijaoui** - Projet Big Data : Analyse du Trafic Urbain et MobilitÃ© Intelligente

---
