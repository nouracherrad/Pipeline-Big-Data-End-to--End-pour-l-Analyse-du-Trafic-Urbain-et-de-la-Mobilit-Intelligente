# ğŸš¦ Pipeline Big Data - Analyse du Trafic Urbain et MobilitÃ© Intelligente

## ğŸ“‹ Table des matiÃ¨res
1. [Vue d'ensemble](#-vue-densemble)
2. [Architecture du systÃ¨me](#ï¸-architecture-du-systÃ¨me)
3. [PrÃ©requis](#-prÃ©requis)
4. [Installation et dÃ©marrage](#-installation-et-dÃ©marrage)
5. [Structure du projet](#-structure-du-projet)
6. [Guide d'utilisation](#-guide-dutilisation)
7. [VÃ©rification du pipeline](#-vÃ©rification-du-pipeline)
8. [Dashboards et visualisation](#-dashboards-et-visualisation)
9. [Troubleshooting](#-troubleshooting)
10. [MÃ©triques et KPIs](#-mÃ©triques-et-kpis)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente un **pipeline Big Data end-to-end** pour l'analyse du trafic urbain dans le cadre d'une Smart City. Il permet de :

- âœ… **Collecter** des donnÃ©es de trafic en temps rÃ©el depuis des capteurs simulÃ©s
- âœ… **IngÃ©rer** les donnÃ©es via Apache Kafka
- âœ… **Stocker** dans un Data Lake HDFS
- âœ… **Traiter** avec Apache Spark
- âœ… **Visualiser** avec Grafana
- âœ… **Orchestrer** avec Apache Airflow
- âœ… **Monitorer** avec Prometheus

### ğŸ“ Contexte du projet

Dans le cadre d'une Smart City, les villes modernes dÃ©ploient des capteurs urbains (camÃ©ras, boucles magnÃ©tiques, capteurs IoT, applications mobiles) pour collecter en continu des donnÃ©es de trafic routier. Ce projet rÃ©pond Ã  la problÃ©matique suivante :

> **Comment concevoir et implÃ©menter un pipeline Big Data capable de collecter des donnÃ©es de trafic urbain en temps rÃ©el, de les stocker dans un Data Lake, de les traiter efficacement, puis de produire des indicateurs exploitables pour la gestion intelligente de la mobilitÃ© ?**

---

## ğŸ—ï¸ Architecture du systÃ¨me

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ARCHITECTURE PIPELINE                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Capteurs IoT   â”‚ â—„â”€â”€ Simulation de 50 capteurs urbains
â”‚   (Producer)    â”‚     GÃ©nÃ¨re des Ã©vÃ©nements toutes les secondes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ JSON events
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Apache Kafka   â”‚ â—„â”€â”€ Streaming temps rÃ©el
â”‚  Topic: traffic â”‚     Gestion des flux IoT
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka Consumer â”‚ â—„â”€â”€ Ingestion et organisation des donnÃ©es
â”‚   + Prometheus  â”‚     MÃ©triques exposÃ©es pour monitoring
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Ã‰criture HDFS
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HDFS (Raw)    â”‚ â—„â”€â”€ Data Lake - Zone Raw
â”‚ /data/raw/trafficâ”‚    Structure partitionnÃ©e par date/heure/zone
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Apache Spark   â”‚ â—„â”€â”€ Traitement distribuÃ© et agrÃ©gation
â”‚  Batch Process  â”‚     Calcul des statistiques et KPIs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Parquet format
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HDFS (Analytics)â”‚ â—„â”€â”€ Zone Analytics - Format optimisÃ©
â”‚ /data/analytics â”‚     RÃ©sultats prÃªts pour l'analyse
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Grafana      â”‚ â—„â”€â”€ Dashboards interactifs
â”‚  + Prometheus   â”‚     Visualisation temps rÃ©el des KPIs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²
         â”‚ Orchestration
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Apache Airflow  â”‚ â—„â”€â”€ Automatisation du pipeline
â”‚   DAG hourly    â”‚     Workflow complet toutes les heures
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Flux de donnÃ©es

1. **GÃ©nÃ©ration** : Le producer Python simule 50 capteurs gÃ©nÃ©rant des Ã©vÃ©nements JSON
2. **Streaming** : Les Ã©vÃ©nements sont publiÃ©s dans Kafka (topic `traffic-events`)
3. **Ingestion** : Le consumer Kafka lit les messages et les Ã©crit dans HDFS
4. **Stockage Raw** : Organisation hiÃ©rarchique par `date`/`heure`/`zone`
5. **Traitement** : Spark lit les donnÃ©es raw et calcule les agrÃ©gations
6. **Stockage Analytics** : RÃ©sultats sauvegardÃ©s en Parquet pour l'analyse
7. **Visualisation** : Grafana affiche les mÃ©triques en temps rÃ©el
8. **Orchestration** : Airflow automatise l'exÃ©cution du pipeline toutes les heures

---

## ğŸ“¦ PrÃ©requis

### Logiciels requis

- **Docker** (version 20.10+)
- **Docker Compose** (version 2.0+)
- **Git**
- **Au moins 8 GB de RAM disponible**
- **20 GB d'espace disque**

### VÃ©rifier les versions

```bash
docker --version
# Docker version 20.10.x ou supÃ©rieur

docker-compose --version
# Docker Compose version 2.x.x ou supÃ©rieur
```

### Configuration systÃ¨me recommandÃ©e

- **CPU** : 4 cÅ“urs minimum
- **RAM** : 8 GB minimum (12 GB recommandÃ©)
- **Disque** : 20 GB d'espace libre
- **OS** : Linux, macOS, ou Windows avec WSL2

---

## ğŸš€ Installation et dÃ©marrage

### 1. Cloner le projet

```bash
git clone <votre-repo>
cd traffic-big-data-pipeline
```

### 2. Structure des dossiers

CrÃ©ez la structure suivante si elle n'existe pas :

```
traffic-big-data-pipeline/
â”œâ”€â”€ producer/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ traffic_producer.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ consumer/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ kafka_to_hdfs.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ spark_job.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ traffic_pipeline.py
â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ provisioning/
â”‚       â”œâ”€â”€ datasources/
â”‚       â”‚   â””â”€â”€ datasources.yml
â”‚       â””â”€â”€ dashboards/
â”‚           â”œâ”€â”€ dashboard.yml
â”‚           â””â”€â”€ traffic_analytics.json
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

### 3. DÃ©marrer les services

```bash
# DÃ©marrer tous les services en arriÃ¨re-plan
docker-compose up -d

# VÃ©rifier que tous les conteneurs sont actifs
docker-compose ps
```

**â±ï¸ Temps de dÃ©marrage estimÃ© : 2-3 minutes**

Vous devriez voir une sortie similaire Ã  :

```
NAME                  STATUS
airflow-postgres      Up (healthy)
airflow-scheduler     Up
airflow-webserver     Up
datanode              Up
grafana               Up
kafka                 Up (healthy)
kafka-consumer        Up
kafka-producer        Up
namenode              Up (healthy)
prometheus            Up
spark                 Up
zookeeper             Up (healthy)
```

### 4. AccÃ©der aux interfaces web

| Service | URL | Identifiants | Description |
|---------|-----|--------------|-------------|
| **Airflow** | http://localhost:8080 | admin / admin | Orchestration du pipeline |
| **Grafana** | http://localhost:3000 | admin / admin | Dashboards et visualisation |
| **Prometheus** | http://localhost:9090 | - | MÃ©triques et monitoring |
| **HDFS NameNode** | http://localhost:9870 | - | Interface web HDFS |
| **Kafka** | localhost:9092 | - | Broker Kafka (CLI uniquement) |

---

## ğŸ“ Structure du projet

### Producer (GÃ©nÃ©rateur de donnÃ©es)

**Fichier** : `producer/traffic_producer.py`

**RÃ´le** : Simuler des capteurs urbains IoT gÃ©nÃ©rant des Ã©vÃ©nements de trafic

**CaractÃ©ristiques** :
- 50 capteurs simulÃ©s (`sensor_001` Ã  `sensor_050`)
- 20 routes diffÃ©rentes (`road_01` Ã  `road_20`)
- 5 zones gÃ©ographiques (Centre, Nord, Sud, Est, Ouest)
- 3 types de routes (autoroute, avenue, rue)
- GÃ©nÃ©ration adaptative selon l'heure :
  - **Heures de pointe** (7h-9h, 17h-20h) : Trafic dense
  - **Heures creuses** (22h-6h) : Trafic faible
  - **Heures normales** : Trafic modÃ©rÃ©

**Exemple d'Ã©vÃ©nement gÃ©nÃ©rÃ©** :

```json
{
  "sensor_id": "sensor_042",
  "road_id": "road_15",
  "road_type": "avenue",
  "zone": "Centre",
  "vehicle_count": 150,
  "average_speed": 25.8,
  "occupancy_rate": 75.4,
  "event_time": "2026-01-10T14:30:45.123456"
}
```

**Commande pour voir les logs** :

```bash
docker-compose logs -f kafka-producer
```

---

### Consumer (HDFS Writer)

**Fichier** : `consumer/kafka_to_hdfs.py`

**RÃ´le** : Consommer les messages Kafka et les Ã©crire dans HDFS

**FonctionnalitÃ©s** :
- Consommation temps rÃ©el depuis Kafka
- Organisation hiÃ©rarchique des donnÃ©es :
  ```
  /data/raw/traffic/
    date=2026-01-10/
      hour=14/
        zone=Centre/
          traffic.json
        zone=Nord/
          traffic.json
  ```
- Buffering pour optimiser les Ã©critures HDFS
- Exposition de mÃ©triques Prometheus sur le port 8000
- Gestion des erreurs et reconnexion automatique

**MÃ©triques exposÃ©es** :
- `traffic_events_total` : Nombre total d'Ã©vÃ©nements traitÃ©s
- `traffic_vehicle_count` : Nombre de vÃ©hicules par zone
- `traffic_average_speed` : Vitesse moyenne par zone
- `traffic_occupancy_rate` : Taux d'occupation par zone
- `traffic_congestion_level` : Niveau de congestion calculÃ©
- `hdfs_bytes_written` : Octets Ã©crits dans HDFS

**Commande pour voir les logs** :

```bash
docker-compose logs -f kafka-consumer
```

---

### Spark Job (Traitement)

**Fichier** : `spark/spark_job.py`

**RÃ´le** : Traiter les donnÃ©es raw et produire des analytics

**Traitements effectuÃ©s** :

1. **Statistiques par zone** :
   - Nombre total d'Ã©vÃ©nements
   - Nombre moyen de vÃ©hicules
   - Vitesse moyenne
   - Taux d'occupation moyen

2. **Statistiques par type de route** :
   - Trafic moyen par type (autoroute, avenue, rue)
   - Vitesse moyenne par type

3. **DÃ©tection des zones congestionnÃ©es** :
   - CritÃ¨res : vitesse < 40 km/h ET occupation > 60%
   - Liste des zones nÃ©cessitant une intervention

**RÃ©sultats sauvegardÃ©s** :
- `/data/analytics/traffic/by_zone/` (format Parquet)
- `/data/analytics/traffic/by_road_type/` (format Parquet)
- `/data/analytics/traffic/congested_zones/` (format Parquet)

**Commande pour exÃ©cuter manuellement** :

```bash
docker exec spark spark-submit \
  --master local[*] \
  --driver-memory 2g \
  /app/spark_job.py
```

---

### Airflow DAG (Orchestration)

**Fichier** : `airflow/dags/traffic_pipeline.py`

**RÃ´le** : Automatiser l'exÃ©cution du pipeline complet

**Workflow du DAG** :

```
check_services â†’ wait_for_data â†’ check_hdfs_data â†’ 
spark_processing â†’ validate_results â†’ generate_report
```

**TÃ¢ches** :

1. **check_services** : VÃ©rifier que tous les conteneurs sont actifs
2. **wait_for_data** : Attendre 60 secondes pour accumuler des donnÃ©es
3. **check_hdfs_data** : VÃ©rifier la prÃ©sence de donnÃ©es dans HDFS
4. **spark_processing** : Lancer le job Spark
5. **validate_results** : VÃ©rifier que les analytics ont Ã©tÃ© gÃ©nÃ©rÃ©s
6. **generate_report** : Produire un rapport d'exÃ©cution

**Configuration** :
- **FrÃ©quence** : Toutes les heures (`@hourly`)
- **PropriÃ©taire** : noura
- **Retries** : 2 tentatives en cas d'Ã©chec
- **Timeout** : 30 minutes par tÃ¢che

**AccÃ¨s** : http://localhost:8080

---

## ğŸ® Guide d'utilisation

### Ã‰tape 1 : DÃ©marrer le pipeline

```bash
# 1. DÃ©marrer tous les services
docker-compose up -d

# 2. VÃ©rifier que tous les conteneurs sont UP
docker-compose ps

# 3. Suivre les logs gÃ©nÃ©raux
docker-compose logs -f
```

**ğŸ“¸ Ã€ capturer en screenshot** :
- RÃ©sultat de `docker-compose ps` montrant tous les services en "Up"
- Logs du producer montrant la gÃ©nÃ©ration d'Ã©vÃ©nements

**Indicateurs de succÃ¨s** :
- âœ… Tous les services affichent "Up" ou "Up (healthy)"
- âœ… Le producer affiche : `EnvoyÃ© : {...}`
- âœ… Le consumer affiche : `ğŸ’¾ Ã‰crit X Ã©vÃ©nements`

---

### Ã‰tape 2 : VÃ©rifier Kafka

```bash
# Lister les topics Kafka
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Vous devriez voir : traffic-events

# Consommer quelques messages pour vÃ©rifier
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic traffic-events \
  --from-beginning \
  --max-messages 5
```

**ğŸ“¸ Ã€ capturer en screenshot** :
- Liste des topics montrant `traffic-events`
- Quelques messages JSON affichÃ©s par le consumer

**Exemple de sortie attendue** :

```json
{"sensor_id":"sensor_003","road_id":"road_12","road_type":"avenue","zone":"Nord","vehicle_count":85,"average_speed":45.2,"occupancy_rate":52.1,"event_time":"2026-01-10T14:30:00"}
```

**VÃ©rifier le lag du consumer** :

```bash
docker exec kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe --group hdfs-consumer-group
```

---

### Ã‰tape 3 : VÃ©rifier HDFS

#### Via ligne de commande

```bash
# 1. Lister la structure principale
docker exec namenode hdfs dfs -ls /data/raw/traffic/

# Sortie attendue :
# drwxr-xr-x   - root supergroup  date=2026-01-10

# 2. Voir les dossiers par date
docker exec namenode hdfs dfs -ls /data/raw/traffic/date=2026-01-10/

# 3. Voir les heures
docker exec namenode hdfs dfs -ls /data/raw/traffic/date=2026-01-10/hour=14/

# 4. Voir les zones
docker exec namenode hdfs dfs -ls /data/raw/traffic/date=2026-01-10/hour=14/

# 5. Lire le contenu d'un fichier (premiÃ¨res lignes)
docker exec namenode hdfs dfs -cat \
  /data/raw/traffic/date=2026-01-10/hour=14/zone=Centre/traffic.json | head -5

# 6. Voir la taille totale des donnÃ©es
docker exec namenode hdfs dfs -du -s -h /data/raw/traffic/
```

**ğŸ“¸ Ã€ capturer en screenshot** :
- Structure hiÃ©rarchique montrant date â†’ hour â†’ zone
- Contenu d'un fichier `traffic.json`
- Taille totale des donnÃ©es stockÃ©es

#### Via interface web HDFS

1. Ouvrir dans un navigateur : http://localhost:9870
2. Cliquer sur **Utilities** dans le menu
3. SÃ©lectionner **Browse the file system**
4. Naviguer vers `/data/raw/traffic/`
5. Explorer la structure date/hour/zone

**ğŸ“¸ Ã€ capturer en screenshot** :
- Page d'accueil HDFS montrant le cluster
- Navigation dans `/data/raw/traffic/`
- DÃ©tails d'un fichier JSON

---

### Ã‰tape 4 : ExÃ©cuter le job Spark

#### MÃ©thode 1 : ExÃ©cution manuelle

```bash
docker exec spark spark-submit \
  --master local[*] \
  --driver-memory 2g \
  --executor-memory 2g \
  /app/spark_job.py
```

**ğŸ“¸ Ã€ capturer en screenshot** :
- Logs Spark montrant :
  - `ğŸ“Š Nombre total d'Ã©vÃ©nements: X`
  - `âœ… Statistiques de trafic par zone:`
  - Tableau avec les statistiques
  - `âœ… Job Spark terminÃ© avec succÃ¨s!`

**Sortie attendue** :

```
ğŸš€ Spark Job - Traitement des donnÃ©es de trafic
ğŸ“– Lecture des donnÃ©es depuis: hdfs://namenode:9000/data/raw/traffic/...
ğŸ“Š Nombre total d'Ã©vÃ©nements: 5432

âœ… Statistiques de trafic par zone:
+------+------------+------------------+---------+--------------+
|zone  |total_events|avg_vehicle_count |avg_speed|avg_occupancy |
+------+------------+------------------+---------+--------------+
|Centre|1234        |125.5             |32.4     |68.2          |
|Nord  |1100        |95.3              |45.7     |52.1          |
...
```

#### MÃ©thode 2 : Via Airflow (recommandÃ©)

Cette mÃ©thode sera dÃ©taillÃ©e Ã  l'Ã©tape 5.

#### VÃ©rifier les rÃ©sultats analytics

```bash
# Lister les dossiers analytics
docker exec namenode hdfs dfs -ls /data/analytics/traffic/

# Vous devriez voir :
# /data/analytics/traffic/by_zone/
# /data/analytics/traffic/by_road_type/
# /data/analytics/traffic/congested_zones/

# Voir la taille des rÃ©sultats
docker exec namenode hdfs dfs -du -s -h /data/analytics/traffic/by_zone/

# Lire quelques rÃ©sultats (format Parquet)
docker exec spark spark-shell --master local[*] <<EOF
val df = spark.read.parquet("hdfs://namenode:9000/data/analytics/traffic/by_zone")
df.show()
EOF
```

**ğŸ“¸ Ã€ capturer en screenshot** :
- Liste des dossiers analytics
- Contenu d'une table (by_zone, by_road_type, ou congested_zones)

---

### Ã‰tape 5 : Utiliser Airflow

#### AccÃ©der Ã  l'interface Airflow

1. Ouvrir dans un navigateur : http://localhost:8080
2. Se connecter avec :
   - **Username** : `admin`
   - **Password** : `admin`

**ğŸ“¸ Ã€ capturer en screenshot** :
- Page de connexion Airflow
- Page d'accueil avec la liste des DAGs

#### Activer le DAG

1. Dans la liste des DAGs, trouver `traffic_pipeline_big_data`
2. Cliquer sur le bouton **Toggle** (interrupteur) Ã  gauche pour l'activer
3. Le DAG devient actif et s'exÃ©cutera automatiquement toutes les heures

**ğŸ“¸ Ã€ capturer en screenshot** :
- DAG activÃ© (interrupteur en bleu/vert)
- Description du DAG : "Pipeline Big Data pour analyse du trafic urbain"

#### Lancer manuellement le DAG

1. Cliquer sur le nom du DAG `traffic_pipeline_big_data`
2. Cliquer sur le bouton **â–¶ï¸ (Play)** en haut Ã  droite
3. SÃ©lectionner **Trigger DAG**
4. Confirmer le lancement

**ğŸ“¸ Ã€ capturer en screenshot** :
- Bouton "Trigger DAG"
- FenÃªtre de confirmation

#### Observer l'exÃ©cution

1. Cliquer sur le DAG pour voir les dÃ©tails
2. Choisir la vue **Graph** pour voir le workflow
3. Observer les tÃ¢ches qui s'exÃ©cutent :
   - ğŸŸ¡ Jaune : En cours
   - ğŸŸ¢ Vert : RÃ©ussi
   - ğŸ”´ Rouge : Ã‰chouÃ©

**ğŸ“¸ Ã€ capturer en screenshot** :
- Vue Graph montrant toutes les tÃ¢ches
- TÃ¢ches en cours d'exÃ©cution (jaune)
- Toutes les tÃ¢ches rÃ©ussies (vert)

#### Vue dÃ©taillÃ©e des logs

1. Cliquer sur une tÃ¢che (ex: `spark_processing`)
2. SÃ©lectionner **Log**
3. Observer les logs dÃ©taillÃ©s de la tÃ¢che

**ğŸ“¸ Ã€ capturer en screenshot** :
- Logs de la tÃ¢che `check_hdfs_data` montrant les fichiers trouvÃ©s
- Logs de la tÃ¢che `spark_processing` montrant le succÃ¨s du job
- Logs de la tÃ¢che `generate_report` montrant le rapport final

**Exemple de log attendu pour `spark_processing`** :

```
[2026-01-10, 14:35:00] {bash.py:123} INFO - ğŸ”¥ Lancement du job Spark...
[2026-01-10, 14:35:05] {bash.py:123} INFO - ğŸ“Š Nombre total d'Ã©vÃ©nements: 5432
[2026-01-10, 14:35:10] {bash.py:123} INFO - âœ… Job Spark terminÃ© avec succÃ¨s
```

#### Vue du calendrier

1. Cliquer sur l'onglet **Calendar**
2. Observer l'historique des exÃ©cutions
3. Chaque case colorÃ©e reprÃ©sente une exÃ©cution :
   - Vert : SuccÃ¨s
   - Rouge : Ã‰chec
   - Blanc : Pas d'exÃ©cution

**ğŸ“¸ Ã€ capturer en screenshot** :
- Vue calendrier montrant plusieurs exÃ©cutions rÃ©ussies

---

### Ã‰tape 6 : Visualiser avec Grafana

#### AccÃ©der Ã  Grafana

1. Ouvrir dans un navigateur : http://localhost:3000
2. Se connecter avec :
   - **Username** : `admin`
   - **Password** : `admin`
3. (Optionnel) Changer le mot de passe ou cliquer sur "Skip"

**ğŸ“¸ Ã€ capturer en screenshot** :
- Page de connexion Grafana
- Page d'accueil de Grafana

#### AccÃ©der au dashboard

1. Cliquer sur le menu hamburger (â˜°) en haut Ã  gauche
2. SÃ©lectionner **Dashboards**
3. Cliquer sur **Traffic Analytics - Smart City**

**ğŸ“¸ Ã€ capturer en screenshot** :
- Liste des dashboards
- Dashboard complet "Traffic Analytics - Smart City"

#### Panels du dashboard

Le dashboard contient 5 panels principaux :

##### 1. Total Ã‰vÃ©nements (Stat Panel)

**Description** : Affiche le nombre total d'Ã©vÃ©nements traitÃ©s depuis le dÃ©marrage

**MÃ©triques** :
- Compteur : `traffic_events_total`
- Seuils de couleur :
  - ğŸŸ¢ Vert : < 1000 Ã©vÃ©nements
  - ğŸŸ¡ Jaune : 1000-5000 Ã©vÃ©nements
  - ğŸ”´ Rouge : > 5000 Ã©vÃ©nements

**ğŸ“¸ Ã€ capturer en screenshot** :
- Panel montrant le compteur total (ex: 8532 Ã©vÃ©nements)

---

##### 2. VÃ©hicules par Zone (Time Series)

**Description** : Graphique temporel montrant l'Ã©volution du nombre de vÃ©hicules par zone

**MÃ©triques** :
- SÃ©rie temporelle : `traffic_vehicle_count`
- Une courbe par zone (Centre, Nord, Sud, Est, Ouest)

**InterprÃ©tation** :
- Pics visibles pendant les heures de pointe
- Tendances diffÃ©rentes selon les zones
- Identification rapide des zones les plus frÃ©quentÃ©es

**ğŸ“¸ Ã€ capturer en screenshot** :
- Graphique avec les 5 courbes de zones
- LÃ©gende montrant les couleurs de chaque zone
- Pic visible pendant les heures de pointe

---

##### 3. Vitesse Moyenne (Gauge)

**Description** : Jauges circulaires montrant la vitesse moyenne par zone

**MÃ©triques** :
- Gauge : `traffic_average_speed`
- Une jauge par zone
- UnitÃ© : km/h

**Seuils de couleur** :
- ğŸ”´ Rouge : < 30 km/h (congestion)
- ğŸŸ¡ Jaune : 30-50 km/h (ralentissement)
- ğŸŸ¢ Vert : > 50 km/h (fluide)

**ğŸ“¸ Ã€ capturer en screenshot** :
- Ensemble des jauges pour toutes les zones
- Au moins une zone en rouge (congestion)
- Au moins une zone en vert (fluide)

---

##### 4. Taux d'Occupation (Time Series)

**Description** : Ã‰volution du taux d'occupation de la route (0-100%)

**MÃ©triques** :
- SÃ©rie temporelle : `traffic_occupancy_rate`
- Une courbe par zone
- Ã‰chelle : 0-100%

**InterprÃ©tation** :
- Occupation Ã©levÃ©e (>70%) = risque de congestion
- Occupation faible (<30%) = trafic fluide

**ğŸ“¸ Ã€ capturer en screenshot** :
- Graphique montrant l'Ã©volution temporelle
- Courbes de diffÃ©rentes couleurs pour chaque zone
- Variation visible selon les heures

---

##### 5. Niveau de Congestion (Gauge)

**Description** : Score composite de congestion calculÃ© (0-100)

**Formule de calcul** :
```
Congestion = 0.4 Ã— (vehicle_count/200Ã—100) 
           + 0.4 Ã— ((110-speed)/110Ã—100) 
           + 0.2 Ã— occupancy_rate
```

**MÃ©triques** :
- Gauge : `traffic_congestion_level`
- Score de 0 Ã  100

**Seuils d'interprÃ©tation** :
- ğŸŸ¢ Vert : 0-40 (fluide)
- ğŸŸ¡ Jaune : 40-70 (modÃ©rÃ©)
- ğŸ”´ Rouge : 70-100 (congestionnÃ©)

**ğŸ“¸ Ã€ capturer en screenshot** :
- Jauges de congestion pour toutes les zones
- Au moins une zone en Ã©tat critique (rouge)

---

#### FonctionnalitÃ©s avancÃ©es de Grafana

##### Filtrage temporel

En haut Ã  droite du dashboard :
1. Cliquer sur la sÃ©lection de temps (ex: "Last 1 hour")
2. Choisir une pÃ©riode :
   - Last 5 minutes
   - Last 15 minutes
   - Last 1 hour
   - Last 3 hours
   - Custom range

**ğŸ“¸ Ã€ capturer en screenshot** :
- Menu de sÃ©lection temporelle
- Dashboard mis Ã  jour avec une pÃ©riode diffÃ©rente

##### RafraÃ®chissement automatique

1. En haut Ã  droite, cliquer sur l'icÃ´ne de rafraÃ®chissement
2. SÃ©lectionner "5s" pour un rafraÃ®chissement toutes les 5 secondes
3. Observer les graphiques se mettre Ã  jour en temps rÃ©el

**ğŸ“¸ Ã€ capturer en screenshot** (optionnel) :
- Indicateur de rafraÃ®chissement automatique actif

##### Zoom sur un graphique

1. Cliquer et glisser sur un graphique pour sÃ©lectionner une pÃ©riode
2. Le graphique zoome automatiquement
3. Cliquer sur "Zoom out" pour revenir

##### Export de dashboard

1. Cliquer sur l'icÃ´ne de partage en haut du dashboard
2. SÃ©lectionner "Export"
3. TÃ©lÃ©charger le fichier JSON

---

### Ã‰tape 7 : VÃ©rifier Prometheus

#### AccÃ©der Ã  Prometheus

1. Ouvrir dans un navigateur : http://localhost:9090
2. Aucune authentification requise

**ğŸ“¸ Ã€ capturer en screenshot** :
- Page d'accueil de Prometheus

#### VÃ©rifier les targets

1. Cliquer sur **Status** dans le menu
2. SÃ©lectionner **Targets**
3. VÃ©rifier que `kafka_consumer_metrics` est en **UP**

**ğŸ“¸ Ã€ capturer en screenshot** :
- Liste des targets
- Target `kafka_consumer_metrics` avec Ã©tat "UP" et endpoint `kafka-consumer:8000`

#### ExÃ©cuter des requÃªtes PromQL

##### RequÃªte 1 : Taux d'Ã©vÃ©nements par seconde

```promql
rate(traffic_events_total[1m])
```

1. Copier la requÃªte dans la barre de recherche
2. Cliquer sur **Execute**
3. SÃ©lectionner l'onglet **Graph** pour voir l'Ã©volution

**ğŸ“¸ Ã€ capturer en screenshot** :
- Graphique montrant le taux d'Ã©vÃ©nements/seconde

---

##### RequÃªte 2 : VÃ©hicules moyens par zone

```promql
avg(traffic_vehicle_count) by (zone)
```

**RÃ©sultat attendu** :
```
{zone="Centre"}    125.5
{zone="Nord"}      95.3
{zone="Sud"}       87.2
{zone="Est"}       102.1
{zone="Ouest"}     78.9
```

**ğŸ“¸ Ã€ capturer en screenshot** :
- Table montrant les valeurs par
